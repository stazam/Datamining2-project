---
title: "Pokročilé metody text miningu"
output: html_notebook
---

# Příprava dat

Podívejme se na recenze k filmům ze stránky IMDB (*Internet Movie Database*), které můžeme najít jako součást balíčku *textdata*. Začněme tedy načtením potřebných balíčků.

```{r}
library(tidytext)
library(textdata)
library(tidyverse)
library(tm)
library(koRpus)
library(koRpus.lang.en)
```

A stáhněme si potřebná data (stáhne se přes 300 MB dat) a podívejme se na prvních 10 záznamů.

```{r}
imdb <- dataset_imdb()

head(imdb, n=10)
```

Data obsahují pouze dvě proměnné. První proměnná značí, jedná-li se o pozitivní nebo negativní recenzi a ve druhé proměnné je uložen samotný text recenze. Navíc přidáme identifikátor původní recenze.

```{r}
imdb <- imdb %>% 
  mutate(id = row_number())
```

Celý dataset obsahuje celkem 25 tisíc recenzí. Pro každou recenzi máme k dispozici hodnocení, zda-li se jedná o pozitivní (7 a více hvězdiček) nebo negativní (4 a méně hvězdiček) recenzi. Navíc žádný film nemá v datasetu více jak 30 recenzí, protože různé recenze ke stejnému filmu mají tendence být silně korelovany.

Protože celý proces je celkově náročný na výpočetní výkon, použijeme jenom menší vzorek (10000 náhodně zvolených recenzí), abychom veškeré výpočty urychlili.

```{r}
# nastaveni generatoru nahodnych cisel
set.seed(42)

imdb_split <- sample(1:25000, 10000, replace=FALSE)

imdb <- imdb %>% 
  inner_join(tibble(id = imdb_split), by="id")
```

Zkontrolujme, že máme zahrnuty pozitivní a negativní recenze v relativně stejném poměru.

```{r}
imdb %>% 
  count(sentiment)
```

A ještě si upravíme identifikátor, aby nabýval hodnot od 1 do 10000.

```{r}
imdb <- imdb %>%
  mutate(id = row_number())
```

Jako další krok provedeme tokenizaci a rovnou se podíváme, jaká nejčastější slova se v datech vyskytují.

```{r}
imdb_tidy <- imdb %>%
  unnest_tokens(word, text)

words <- imdb_tidy %>% 
  count(word, sort=TRUE)

words
```

Nelze si nevšimnout, že většina nejčastějších slov se řadí mezi tzv. stopwords, které za okamžik odstraníme. Nejprve však ještě provedeme lemmatizaci, abychom sjednotili stejná slova, která mají jiný tvar. Tato operace může trvat na velkém vzorku i několik minut.

```{r message=FALSE}
set.kRp.env(TT.cmd="manual", TT.options=list(path="C:\\TreeTagger", preset="en"), lang="en")

lemmatization <- treetag(words$word, treetagger="manual", format="obj",
                      TT.tknz=FALSE , lang="en",
                      TT.options=list(path="C:/treeTagger", preset="en"))

lemmatization@tokens
```

Lemmatizovaná slova najdeme ve sloupci *lemma*. Vytvořme nyní slovník *token* - *lemma*, který potom spojíme s původním datasetem. Musíme si dát však pozor na některé aspekty zvoleného algoritmu, které musíme zohlednit v našem slovníku.

Za prvé algoritmus k některým slovům nenašel jejich základní tvar. Ty poznáme podle hodnoty *<unknown>* ve sloupci *lemma* a odstraníme je ze slovníku.

Za druhé máme k některým slovům na výběr více variant lemmatizovaných slov. Ty poznáme podle hodnoty *slovo1|slovo2|slovo3* ve sloupci *lemma* a v tomto případě vezmeme jenom první možnost.

A za třetí slovník obsahuje i různé netextové prvky (apostrofy, číslovky), které ze slovníku taktéž odstraníme.

```{r message=FALSE}
lemmatization_dict <- tibble(word=lemmatization@tokens$token, lemma=lemmatization@tokens$lemma) %>% 
  filter(lemma != "<unknown>") %>% 
  mutate(lemma = str_replace(lemma, "\\|.+", "")) %>% 
  filter(str_detect(lemma, "[^a-z]", negate=TRUE)) %>% 
  group_by(word) %>% 
  slice(1)

lemmatization_dict
```

Když máme připravený slovník, tak ho spojíme s původním datasetem. 

```{r}
imdb_final <- imdb_tidy %>%
  inner_join(lemmatization_dict, by="word")

imdb_final
```

V dalším kroku odstraníme stopwords.

```{r}
imdb_final <- imdb_final %>%
  mutate(word = lemma) %>% 
  select(sentiment, id, word) %>% 
  anti_join(stop_words, by="word")

imdb_final %>% 
  count(word, sort=TRUE)
```

Po odstranění stopwords je nejčastějším slovem *br*. Jedná se však o html tag, který značí odřádkování a z další analýzy jej odstraníme.

```{r}
imdb_final <- imdb_final %>%
  filter(word != "br")

imdb_final %>% 
  count(word, sort=TRUE)
```

Jako poslední krok při přípravě dat přejmenujeme proměnnou *sentiment* na *rating*, která by se nám mohla plést se stejně pojmenovanou proměnnou v sentimentových slovnících.

```{r}
imdb_final <- imdb_final %>%
  rename(rating = sentiment)

imdb_final
```

# Analýza sentimentu

Zkusme se rychle podívat na sentiment upraveného datasetu. Jako první si vykreslíme 10 nejčastějších slov v pozitivních a negativních recenzích.

```{r}
imdb_final %>%
  count(rating, word, sort=TRUE) %>% 
  group_by(rating) %>% 
  top_n(10,n ) %>% 
  ungroup() %>% 
  mutate(word = reorder(word, n)) %>% 
  ggplot(aes(x=word, y=n, fill=factor(rating))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~rating, scales = "free_y") +
  scale_fill_manual(
    values=c("red2", "limegreen")
    ) +
  coord_flip()
```

Oblíbený způsob vizualizace slov v rozdílných kategoriích je i tzv. *wordcloud*, který je dostupný ve stejnojmenném balíčku.

```{r}
# install.packages("wordcloud")
library(wordcloud)

par(mfrow=c(1,2), mar=c(0,0,0,0))

imdb_final %>%
  filter(rating == "neg") %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 100, random.order=FALSE, color="red2"))

imdb_final %>%
  filter(rating == "pos") %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 100, random.order=FALSE, color="limegreen"))
```

Nejprve se podívejme na slovník *AFINN*, který má pro každý záznam ve slovníku přiřazené číslo od -5 do 5 podle toho, jak moc je dané slovo negativní nebo pozitivní.

Pro každou recenzi si vypočítáme celkové skóre jako součet sentimentů pro všechny slova vážené četností. Toto celkové skóre můžeme zobrazit v boxplotu a porovnat hodnoty pro pozitivní a negativní recenze.

```{r message=FALSE}
imdb_final %>%
  count(rating, id, word) %>% 
  inner_join(get_sentiments("afinn"), by="word") %>% 
  mutate(score = n*value) %>% 
  group_by(rating, id) %>% 
  summarise(total_score = sum(score)) %>% 
  ggplot(aes(x=factor(rating), y=total_score, color=factor(rating))) +
  geom_boxplot(show.legend=FALSE) +
  scale_color_manual(
    values=c("red2", "limegreen")) +
  labs(
    x="Rating",
    y="Total score"  )
```

Zkusme se ještě podívat blíže, jak odpovídá hodnota ze slovníku *AFINN* tomu, co pozorujeme v datech. Pro každý výskyt daného slova v pozitivní recenzi přičteme ke skóre daného slova +1 a naopak za výskyt v negativním slově odečteme -1. Takto získané skóre si porovnáme s hodnotami z *AFINN* slovníku.

```{r message=FALSE}
score_comparison <- imdb_final %>%
  group_by(rating, word) %>% 
  summarise(n = sum(n())) %>% 
  mutate(n = if_else(rating == "neg", -n, n)) %>% 
  group_by(word) %>% 
  summarise(n = sum(n)) %>% 
  inner_join(get_sentiments("afinn"), by="word")
  
ggplot(data=score_comparison, aes(x=value, y=n)) +
  geom_jitter() +
  geom_text(
    data = score_comparison %>%
      filter(!between(n, -500, 500)),
    aes(x=value, y=n, label=word)) +
  labs(
    x="AFINN score",
    y="Score from data")
``` 
 
Jako druhý v pořadí jsme si minule představili slovník *bing*, který slovo rozděluje na pozitivní a negativní. Podívejme se, jak dobře tento slovník umí odhadnout, jestli je daná recenze pozitivní nebo negativní. Vypočítáme si kumulativní skóre tak, že každé pozitivní slovo nám zvýší skóre o 1 a naopak negativní slovo sníží skóre o 1. Toto kumulativní skóre si vykreslíme a podíváme se, jestli se pozitivní recenze s přibývajícími slovy stává ještě pozitivnější a nebo naopak.

```{r}
set.seed(42)

imdb_final %>%
  filter(id %in% sample(1:10000, 100)) %>% 
  inner_join(get_sentiments("bing"), by="word") %>% 
  group_by(rating, id) %>% 
  mutate(
    score = if_else(sentiment == "positive", 1, -1),
    rank = row_number(),
    cum_score = cumsum(score)) %>% 
  ggplot(aes(x=rank, y=cum_score, group=id, col=rating)) +
  geom_step(alpha=0.5, show.legend=FALSE) +
    scale_color_manual(
    values=c("red2", "limegreen")) +
  labs(
    x="Number of words",
    y="Cummulative score")
```

# Klasifikace

Podívejme se na klasifikační úlohu, kdy se budeme snažit natrénovat rozhodovací strom, který na základě obsahu (slov) dané recenze rozhodne, jestli se jedná o pozitivní nebo negativní recenzi.

Začneme s tím, že si převedeme text do vhodné podoby, která může sloužit jako vstup do našeho modelu, takže vytvoříme *document-term matici*.

```{r}
imdb_dtm <- imdb_final %>%
  group_by(id) %>%
  count(word) %>%
  cast_dtm(id, word, n)

inspect(imdb_dtm)
```

Vytvořená document-term matice má přes 26 tisíc sloupců. My bychom chtěli ale tento počet snížit, abychom urychlili odhadt modelu a odstraníme tedy slova, která chybí ve více jak 95 % dokumentů (recenzí). Tímto se nám počet sloupců sníží na 198.

```{r}
imdb_dtm <- removeSparseTerms(imdb_dtm, sparse = .95)

inspect(imdb_dtm)
```

Data je potřeba rozdělit si na trénovací a testovací vzorek v poměru 60:40. Trénovací vzorek slouží k odhadu modelu. Model se ovšem validuje na jiném vzorku dat, než na kterém byl model odhadnut. Na tyto účely slouží právě testovací vzorek. Použijeme knihovnu *rsample*, která nám s tímto rozdělením pomůže.

```{r}
set.seed(42)

split <- sort(sample(1:10000, 6000, replace=FALSE))

imdb_train <- as.matrix(imdb_dtm)[split,]
imdb_test <- as.matrix(imdb_dtm)[-split,]

rating_train <- imdb_final %>% 
  select(rating, id) %>% 
  unique() %>% 
  filter(id %in% split)
  
rating_test <- imdb_final %>% 
  select(rating, id) %>% 
  unique() %>% 
  filter(!id %in% split)
```

Máme všechno připravené a nyní si odhadneme rozhodovací strom. Budeme používat funkci *train* z balíčku *caret*.

```{r}
# install.packages("caret")
library(caret)

classifier_tree <- train(x=imdb_train,
                    y=as.factor(rating_train$rating),
                    method="rpart",
                    cp=0.002,
                    maxdepth=20)
```

V dalším kroku si můžeme prohlédnout detaily odhadnutého modelu.

```{r}
classifier_tree$finalModel
```
A vykreslit ho.

```{r}
par(mar=c(0,0,0,0))

plot(classifier_tree$finalModel)
text(classifier_tree$finalModel)
```
Podívejme se i na rozhodovací les, který bude tvořit 10 rozhodovacích stromů.

```{r}
classifier_forest <- train(x=imdb_train,
                    y=as.factor(rating_train$rating),
                    method="ranger",
                    num.trees=10,
                    importance="impurity")
```

Prohlédněme si detaily odhadnutého modelu.

```{r}
classifier_forest$finalModel
```

Můžeme se podívat na slova (proměnné), které jsou dle rozhodovacího lesu nejdůležitější.

```{r}
classifier_forest$finalModel %>%
  ranger::importance() %>%
  enframe(name="variable", value="varimp") %>%
  top_n(n=20, wt=varimp) %>%
  ggplot(aes(x=fct_reorder(variable, varimp), y=varimp)) +
  geom_col() +
  coord_flip() +
  labs(x="Word",
       y="Variable importance (higher is more important)")
```
Nyní pomocí se podívejme, jak by odhadnuté modely klasifikují testovací data.

```{r}
predictions_tree <- predict(classifier_tree, newdata=imdb_test)
predictions_forest <- predict(classifier_forest, newdata=imdb_test)
```

Vektor *predictions* obsahuje predikce, takže ke každému záznamu dostaneme buď *pos* pro predikci pozitivní recenze, nebo *neg* pro predikci negativní recenze. Můžeme se podívat, jak velká část recenzí byla správně predikována.

Pro rozhodovací strom:

```{r}
# install.packages("yardstick")
library(yardstick)

rating_test %>% 
  mutate(prediction = as.factor(predictions_tree),
         rating = as.factor(rating)) %>% 
  conf_mat(rating, prediction)
```

Pro rozhodovací les:

```{r}
rating_test %>% 
  mutate(prediction = as.factor(predictions_forest),
         rating = as.factor(rating)) %>% 
  conf_mat(rating, prediction)
```

